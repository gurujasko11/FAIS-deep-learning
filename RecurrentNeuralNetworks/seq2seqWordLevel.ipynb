{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gurujasko11/FAIS-deep-learning/blob/master/RecurrentNeuralNetworks/seq2seqWordLevel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE5zh5ZYtz4v",
        "colab_type": "code",
        "outputId": "23bc84ce-42a0-434d-cf0b-13afb8899f0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Embedding, Dense\n",
        "from keras.utils import plot_model\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "num_samples = 5000  # Number of samples to train on.\n",
        "\n",
        "data_path = '/content/pol.txt'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULTl2unbupyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "lines_eng = []\n",
        "lines_pol = []\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "  input_text, target_text, ignore = line.split('\\t')[:3]\n",
        "  lines_eng.append(input_text)\n",
        "  lines_pol.append('START_ '+target_text+ ' _END')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-1NWmyYuiou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_eng_words=set()\n",
        "for eng in lines_eng:\n",
        "    for word in eng.split():\n",
        "        if word not in all_eng_words:\n",
        "            all_eng_words.add(word)\n",
        "    \n",
        "all_pol_words=set()\n",
        "for pol in lines_pol:\n",
        "    for word in pol.split():\n",
        "        if word not in all_pol_words:\n",
        "            all_pol_words.add(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF_WYRJCwlbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_words = sorted(list(all_eng_words))\n",
        "target_words = sorted(list(all_pol_words))\n",
        "num_encoder_tokens = len(all_eng_words)\n",
        "num_decoder_tokens = len(all_pol_words)\n",
        "max_lenght_eng = max([len(txt.split()) for txt in lines_eng])\n",
        "max_lenght_pol = max([len(txt.split()) for txt in lines_pol])\n",
        "\n",
        "input_token_index = dict(\n",
        "    [(word, i) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict(\n",
        "    [(word, i) for i, word in enumerate(target_words)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLassIZfws9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input_data = np.zeros(\n",
        "    (len(lines_eng), max_lenght_eng),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(lines_pol), max_lenght_pol),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(lines_pol), max_lenght_pol, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(lines_eng, lines_pol)):\n",
        "    for t, word in enumerate(input_text.split()):\n",
        "        encoder_input_data[i, t] = input_token_index[word]\n",
        "    for t, word in enumerate(target_text.split()):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t] = target_token_index[word]\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[word]] = 1."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC-Brtwubayw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "ac674b57-e924-4165-a82b-ef9aef0704f9"
      },
      "source": [
        "embedding_size = 50\n",
        "from keras.layers import Input, LSTM, Embedding, Dense\n",
        "from keras.models import Model\n",
        "from keras.utils import plot_model\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "# English words embedding\n",
        "en_x =  Embedding(num_encoder_tokens, embedding_size)(encoder_inputs)\n",
        "# Encoder lstm\n",
        "encoder = LSTM(150, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(en_x)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "# french word embeddings\n",
        "dex =  Embedding(num_decoder_tokens, embedding_size)\n",
        "final_dex = dex(decoder_inputs)\n",
        "# decoder lstm\n",
        "decoder_lstm = LSTM(150, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(final_dex,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "# While training, model takes eng and french words and outputs #translated french word\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "# rmsprop is preferred for nlp tasks\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXuLom18bkXA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c157515e-bfdf-45c9-bf8b-a6a535d38ce5"
      },
      "source": [
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=128,\n",
        "          epochs=50,\n",
        "          validation_split=0.20)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 4000 samples, validate on 1000 samples\n",
            "Epoch 1/50\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "4000/4000 [==============================] - 4s 1ms/step - loss: 2.0985 - acc: 0.0880 - val_loss: 2.2134 - val_acc: 0.0909\n",
            "Epoch 2/50\n",
            "4000/4000 [==============================] - 2s 575us/step - loss: 1.7402 - acc: 0.0964 - val_loss: 2.2235 - val_acc: 0.0992\n",
            "Epoch 3/50\n",
            "4000/4000 [==============================] - 2s 577us/step - loss: 1.6813 - acc: 0.0997 - val_loss: 2.2453 - val_acc: 0.0993\n",
            "Epoch 4/50\n",
            "4000/4000 [==============================] - 2s 581us/step - loss: 1.6314 - acc: 0.1005 - val_loss: 2.2361 - val_acc: 0.0994\n",
            "Epoch 5/50\n",
            "4000/4000 [==============================] - 2s 575us/step - loss: 1.5808 - acc: 0.1038 - val_loss: 2.2550 - val_acc: 0.1025\n",
            "Epoch 6/50\n",
            "4000/4000 [==============================] - 2s 575us/step - loss: 1.5285 - acc: 0.1060 - val_loss: 2.2214 - val_acc: 0.1040\n",
            "Epoch 7/50\n",
            "4000/4000 [==============================] - 2s 577us/step - loss: 1.4812 - acc: 0.1085 - val_loss: 2.2065 - val_acc: 0.1094\n",
            "Epoch 8/50\n",
            "4000/4000 [==============================] - 2s 574us/step - loss: 1.4406 - acc: 0.1111 - val_loss: 2.1792 - val_acc: 0.1109\n",
            "Epoch 9/50\n",
            "4000/4000 [==============================] - 2s 569us/step - loss: 1.4034 - acc: 0.1133 - val_loss: 2.1712 - val_acc: 0.1117\n",
            "Epoch 10/50\n",
            "4000/4000 [==============================] - 2s 579us/step - loss: 1.3719 - acc: 0.1150 - val_loss: 2.1927 - val_acc: 0.1132\n",
            "Epoch 11/50\n",
            "4000/4000 [==============================] - 2s 579us/step - loss: 1.3417 - acc: 0.1159 - val_loss: 2.2084 - val_acc: 0.1143\n",
            "Epoch 12/50\n",
            "4000/4000 [==============================] - 2s 578us/step - loss: 1.3157 - acc: 0.1179 - val_loss: 2.2351 - val_acc: 0.1160\n",
            "Epoch 13/50\n",
            "4000/4000 [==============================] - 2s 573us/step - loss: 1.2902 - acc: 0.1181 - val_loss: 2.2232 - val_acc: 0.1182\n",
            "Epoch 14/50\n",
            "4000/4000 [==============================] - 2s 578us/step - loss: 1.2648 - acc: 0.1195 - val_loss: 2.2424 - val_acc: 0.1147\n",
            "Epoch 15/50\n",
            "4000/4000 [==============================] - 2s 576us/step - loss: 1.2419 - acc: 0.1208 - val_loss: 2.2432 - val_acc: 0.1153\n",
            "Epoch 16/50\n",
            "4000/4000 [==============================] - 2s 578us/step - loss: 1.2235 - acc: 0.1218 - val_loss: 2.2620 - val_acc: 0.1165\n",
            "Epoch 17/50\n",
            "4000/4000 [==============================] - 2s 577us/step - loss: 1.2045 - acc: 0.1227 - val_loss: 2.2697 - val_acc: 0.1122\n",
            "Epoch 18/50\n",
            "4000/4000 [==============================] - 2s 575us/step - loss: 1.1866 - acc: 0.1240 - val_loss: 2.2905 - val_acc: 0.1122\n",
            "Epoch 19/50\n",
            "4000/4000 [==============================] - 2s 584us/step - loss: 1.1671 - acc: 0.1258 - val_loss: 2.2875 - val_acc: 0.1159\n",
            "Epoch 20/50\n",
            "4000/4000 [==============================] - 2s 572us/step - loss: 1.1528 - acc: 0.1272 - val_loss: 2.2890 - val_acc: 0.1190\n",
            "Epoch 21/50\n",
            "4000/4000 [==============================] - 2s 574us/step - loss: 1.1353 - acc: 0.1289 - val_loss: 2.2957 - val_acc: 0.1205\n",
            "Epoch 22/50\n",
            "4000/4000 [==============================] - 2s 574us/step - loss: 1.1197 - acc: 0.1311 - val_loss: 2.2988 - val_acc: 0.1208\n",
            "Epoch 23/50\n",
            "4000/4000 [==============================] - 2s 573us/step - loss: 1.1030 - acc: 0.1331 - val_loss: 2.3209 - val_acc: 0.1139\n",
            "Epoch 24/50\n",
            "4000/4000 [==============================] - 2s 582us/step - loss: 1.0879 - acc: 0.1356 - val_loss: 2.3160 - val_acc: 0.1154\n",
            "Epoch 25/50\n",
            "4000/4000 [==============================] - 2s 573us/step - loss: 1.0713 - acc: 0.1373 - val_loss: 2.3271 - val_acc: 0.1190\n",
            "Epoch 26/50\n",
            "4000/4000 [==============================] - 2s 572us/step - loss: 1.0568 - acc: 0.1389 - val_loss: 2.3348 - val_acc: 0.1195\n",
            "Epoch 27/50\n",
            "4000/4000 [==============================] - 2s 585us/step - loss: 1.0413 - acc: 0.1414 - val_loss: 2.3378 - val_acc: 0.1195\n",
            "Epoch 28/50\n",
            "4000/4000 [==============================] - 2s 579us/step - loss: 1.0261 - acc: 0.1442 - val_loss: 2.3379 - val_acc: 0.1214\n",
            "Epoch 29/50\n",
            "4000/4000 [==============================] - 2s 574us/step - loss: 1.0090 - acc: 0.1461 - val_loss: 2.3376 - val_acc: 0.1219\n",
            "Epoch 30/50\n",
            "4000/4000 [==============================] - 2s 577us/step - loss: 0.9937 - acc: 0.1483 - val_loss: 2.3389 - val_acc: 0.1200\n",
            "Epoch 31/50\n",
            "4000/4000 [==============================] - 2s 571us/step - loss: 0.9796 - acc: 0.1493 - val_loss: 2.3372 - val_acc: 0.1218\n",
            "Epoch 32/50\n",
            "4000/4000 [==============================] - 2s 574us/step - loss: 0.9656 - acc: 0.1508 - val_loss: 2.3538 - val_acc: 0.1227\n",
            "Epoch 33/50\n",
            "4000/4000 [==============================] - 2s 577us/step - loss: 0.9517 - acc: 0.1533 - val_loss: 2.3442 - val_acc: 0.1209\n",
            "Epoch 34/50\n",
            "4000/4000 [==============================] - 2s 581us/step - loss: 0.9393 - acc: 0.1537 - val_loss: 2.3608 - val_acc: 0.1165\n",
            "Epoch 35/50\n",
            "4000/4000 [==============================] - 2s 578us/step - loss: 0.9242 - acc: 0.1555 - val_loss: 2.3627 - val_acc: 0.1167\n",
            "Epoch 36/50\n",
            "4000/4000 [==============================] - 2s 575us/step - loss: 0.9124 - acc: 0.1563 - val_loss: 2.3658 - val_acc: 0.1187\n",
            "Epoch 37/50\n",
            "4000/4000 [==============================] - 2s 577us/step - loss: 0.8993 - acc: 0.1584 - val_loss: 2.3567 - val_acc: 0.1198\n",
            "Epoch 38/50\n",
            "4000/4000 [==============================] - 2s 580us/step - loss: 0.8872 - acc: 0.1600 - val_loss: 2.3877 - val_acc: 0.1115\n",
            "Epoch 39/50\n",
            "4000/4000 [==============================] - 2s 581us/step - loss: 0.8738 - acc: 0.1617 - val_loss: 2.3798 - val_acc: 0.1157\n",
            "Epoch 40/50\n",
            "4000/4000 [==============================] - 2s 578us/step - loss: 0.8644 - acc: 0.1624 - val_loss: 2.3847 - val_acc: 0.1141\n",
            "Epoch 41/50\n",
            "4000/4000 [==============================] - 2s 579us/step - loss: 0.8511 - acc: 0.1648 - val_loss: 2.3795 - val_acc: 0.1154\n",
            "Epoch 42/50\n",
            "4000/4000 [==============================] - 2s 571us/step - loss: 0.8418 - acc: 0.1651 - val_loss: 2.3878 - val_acc: 0.1131\n",
            "Epoch 43/50\n",
            "4000/4000 [==============================] - 2s 574us/step - loss: 0.8300 - acc: 0.1669 - val_loss: 2.3978 - val_acc: 0.1149\n",
            "Epoch 44/50\n",
            "4000/4000 [==============================] - 2s 575us/step - loss: 0.8204 - acc: 0.1687 - val_loss: 2.4095 - val_acc: 0.1102\n",
            "Epoch 45/50\n",
            "4000/4000 [==============================] - 2s 576us/step - loss: 0.8085 - acc: 0.1702 - val_loss: 2.4113 - val_acc: 0.1092\n",
            "Epoch 46/50\n",
            "4000/4000 [==============================] - 2s 575us/step - loss: 0.7984 - acc: 0.1711 - val_loss: 2.4133 - val_acc: 0.1123\n",
            "Epoch 47/50\n",
            "4000/4000 [==============================] - 2s 572us/step - loss: 0.7884 - acc: 0.1720 - val_loss: 2.4212 - val_acc: 0.1099\n",
            "Epoch 48/50\n",
            "4000/4000 [==============================] - 2s 577us/step - loss: 0.7768 - acc: 0.1740 - val_loss: 2.4117 - val_acc: 0.1114\n",
            "Epoch 49/50\n",
            "4000/4000 [==============================] - 2s 580us/step - loss: 0.7656 - acc: 0.1758 - val_loss: 2.4364 - val_acc: 0.1091\n",
            "Epoch 50/50\n",
            "4000/4000 [==============================] - 2s 580us/step - loss: 0.7550 - acc: 0.1772 - val_loss: 2.4234 - val_acc: 0.1097\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa5ff266eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyoNbMq3bvEt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "fed77638-dd4a-4f7c-934f-a5d36bdcdf09"
      },
      "source": [
        "# define the encoder model \n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "encoder_model.summary()\n",
        "# Redefine the decoder model with decoder will be getting below inputs from encoder while in prediction\n",
        "decoder_state_input_h = Input(shape=(150,))\n",
        "decoder_state_input_c = Input(shape=(150,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "final_dex2= dex(decoder_inputs)\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(final_dex2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "# sampling model will take encoder states and decoder_input(seed initially) and output the predictions(french word index) We dont care about decoder_states2\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)\n",
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, None)              0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, None, 50)          144250    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                [(None, 150), (None, 150) 120600    \n",
            "=================================================================\n",
            "Total params: 264,850\n",
            "Trainable params: 264,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rw8rHLY4fA8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = target_token_index['START_']\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "    # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "    # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '_END' or\n",
        "           len(decoded_sentence) > 52):\n",
        "            stop_condition = True\n",
        "    # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "    # Update states\n",
        "        states_value = [h, c]\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XgEHZjM4iwG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b93c6c87-aab7-4a18-a2fd-68e0d52281ae"
      },
      "source": [
        "for seq_index in range(100, 200):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', lines_eng[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: Welcome.\n",
            "Decoded sentence:  Ptaki śpiewają. _END\n",
            "-\n",
            "Input sentence: Who ate?\n",
            "Decoded sentence:  Kto to zrobić. _END\n",
            "-\n",
            "Input sentence: Who won?\n",
            "Decoded sentence:  Kto to zrobić. _END\n",
            "-\n",
            "Input sentence: You run.\n",
            "Decoded sentence:  Poproszę dalej. _END\n",
            "-\n",
            "Input sentence: You won.\n",
            "Decoded sentence:  Jedz powoli. _END\n",
            "-\n",
            "Input sentence: Back off!\n",
            "Decoded sentence:  Idź w wkrótce. _END\n",
            "-\n",
            "Input sentence: Back off.\n",
            "Decoded sentence:  Proszę w dużo. _END\n",
            "-\n",
            "Input sentence: Be still.\n",
            "Decoded sentence:  Bądź ostrożny. _END\n",
            "-\n",
            "Input sentence: Call Tom.\n",
            "Decoded sentence:  Chodź tutaj. _END\n",
            "-\n",
            "Input sentence: Cheer up!\n",
            "Decoded sentence:  Bądź ostrożny. _END\n",
            "-\n",
            "Input sentence: Cool off!\n",
            "Decoded sentence:  Proszę w gruby. _END\n",
            "-\n",
            "Input sentence: Cuff him.\n",
            "Decoded sentence:  Wyglądasz na dużo. _END\n",
            "-\n",
            "Input sentence: Drive on.\n",
            "Decoded sentence:  Jedź dalej. _END\n",
            "-\n",
            "Input sentence: Find Tom.\n",
            "Decoded sentence:  Pocałuj Toma. _END\n",
            "-\n",
            "Input sentence: Fix this.\n",
            "Decoded sentence:  Weź to. _END\n",
            "-\n",
            "Input sentence: Get down!\n",
            "Decoded sentence:  Pomóż powoli. _END\n",
            "-\n",
            "Input sentence: Get down.\n",
            "Decoded sentence:  Usiądź do domu. _END\n",
            "-\n",
            "Input sentence: Get lost!\n",
            "Decoded sentence:  Idź w siebie. _END\n",
            "-\n",
            "Input sentence: Get lost.\n",
            "Decoded sentence:  Usiądź do domu. _END\n",
            "-\n",
            "Input sentence: Get real!\n",
            "Decoded sentence:  Idź do mną. _END\n",
            "-\n",
            "Input sentence: Go ahead!\n",
            "Decoded sentence:  Zacznij w dół. _END\n",
            "-\n",
            "Input sentence: Good job!\n",
            "Decoded sentence:  Pomóż dzięki. _END\n",
            "-\n",
            "Input sentence: Grab Tom.\n",
            "Decoded sentence:  Weź Toma. _END\n",
            "-\n",
            "Input sentence: Grab him.\n",
            "Decoded sentence:  Proszę w dużo. _END\n",
            "-\n",
            "Input sentence: Have fun.\n",
            "Decoded sentence:  Jedź dalej. _END\n",
            "-\n",
            "Input sentence: He tries.\n",
            "Decoded sentence:  On ma ciekaw. _END\n",
            "-\n",
            "Input sentence: He tries.\n",
            "Decoded sentence:  On ma ciekaw. _END\n",
            "-\n",
            "Input sentence: Help Tom.\n",
            "Decoded sentence:  Pocałuj Toma. _END\n",
            "-\n",
            "Input sentence: How cute!\n",
            "Decoded sentence:  Jak to zrobić. _END\n",
            "-\n",
            "Input sentence: How deep?\n",
            "Decoded sentence:  Jak to zrobić. _END\n",
            "-\n",
            "Input sentence: How nice!\n",
            "Decoded sentence:  Jak to zrobić. _END\n",
            "-\n",
            "Input sentence: Hurry up.\n",
            "Decoded sentence:  Zacznij w wkrótce. _END\n",
            "-\n",
            "Input sentence: I am hot.\n",
            "Decoded sentence:  Jestem z Rosji. _END\n",
            "-\n",
            "Input sentence: I am hot.\n",
            "Decoded sentence:  Jestem z Rosji. _END\n",
            "-\n",
            "Input sentence: I did it.\n",
            "Decoded sentence:  Ja za mną? _END\n",
            "-\n",
            "Input sentence: I forgot.\n",
            "Decoded sentence:  Zacznij więcej dłoń. _END\n",
            "-\n",
            "Input sentence: I get it.\n",
            "Decoded sentence:  Będę za dużo. _END\n",
            "-\n",
            "Input sentence: I got it.\n",
            "Decoded sentence:  Ja za dużo. _END\n",
            "-\n",
            "Input sentence: I smiled.\n",
            "Decoded sentence:  Ja za mną? _END\n",
            "-\n",
            "Input sentence: I stayed.\n",
            "Decoded sentence:  Coś jeszcze? _END\n",
            "-\n",
            "Input sentence: I'll pay.\n",
            "Decoded sentence:  Ja za mną? _END\n",
            "-\n",
            "Input sentence: I'll try.\n",
            "Decoded sentence:  Chodź w mną. _END\n",
            "-\n",
            "Input sentence: I'm busy.\n",
            "Decoded sentence:  Jestem prawie gotowy. _END\n",
            "-\n",
            "Input sentence: I'm busy.\n",
            "Decoded sentence:  Jestem prawie gotowy. _END\n",
            "-\n",
            "Input sentence: I'm cool.\n",
            "Decoded sentence:  Jestem w gotowy. _END\n",
            "-\n",
            "Input sentence: I'm done.\n",
            "Decoded sentence:  Mam siostrami? _END\n",
            "-\n",
            "Input sentence: I'm fair.\n",
            "Decoded sentence:  Jestem w gotowy. _END\n",
            "-\n",
            "Input sentence: I'm free!\n",
            "Decoded sentence:  Jestem z Rosji. _END\n",
            "-\n",
            "Input sentence: I'm full.\n",
            "Decoded sentence:  Jestem z Rosji. _END\n",
            "-\n",
            "Input sentence: I'm glad.\n",
            "Decoded sentence:  Przestań za tobą. _END\n",
            "-\n",
            "Input sentence: I'm here.\n",
            "Decoded sentence:  Jestem w domu. _END\n",
            "-\n",
            "Input sentence: I'm home.\n",
            "Decoded sentence:  Jestem w domu. _END\n",
            "-\n",
            "Input sentence: I'm hurt.\n",
            "Decoded sentence:  Jestem prawie gotowy. _END\n",
            "-\n",
            "Input sentence: I'm late.\n",
            "Decoded sentence:  Jestem w spóźniony. _END\n",
            "-\n",
            "Input sentence: I'm lost.\n",
            "Decoded sentence:  Jestem w domu. _END\n",
            "-\n",
            "Input sentence: I'm lost.\n",
            "Decoded sentence:  Jestem w domu. _END\n",
            "-\n",
            "Input sentence: I'm lost.\n",
            "Decoded sentence:  Jestem w domu. _END\n",
            "-\n",
            "Input sentence: I'm mean.\n",
            "Decoded sentence:  Jestem z Rosji. _END\n",
            "-\n",
            "Input sentence: I'm next.\n",
            "Decoded sentence:  Jestem z gotowy. _END\n",
            "-\n",
            "Input sentence: I'm poor.\n",
            "Decoded sentence:  Jestem z Rosji. _END\n",
            "-\n",
            "Input sentence: I'm rich.\n",
            "Decoded sentence:  Jestem prawie gotowy. _END\n",
            "-\n",
            "Input sentence: I'm safe.\n",
            "Decoded sentence:  Jestem prawie gotowy. _END\n",
            "-\n",
            "Input sentence: I'm sick.\n",
            "Decoded sentence:  Jestem z Rosji. _END\n",
            "-\n",
            "Input sentence: I'm sure.\n",
            "Decoded sentence:  Jestem z Rosji. _END\n",
            "-\n",
            "Input sentence: I'm warm.\n",
            "Decoded sentence:  Jesteś szalony. _END\n",
            "-\n",
            "Input sentence: I'm weak.\n",
            "Decoded sentence:  Jestem prawie gotowy. _END\n",
            "-\n",
            "Input sentence: I'm wise.\n",
            "Decoded sentence:  Jestem z Rosji. _END\n",
            "-\n",
            "Input sentence: I've won.\n",
            "Decoded sentence:  Pomóż powoli. _END\n",
            "-\n",
            "Input sentence: It works.\n",
            "Decoded sentence:  To działa. _END\n",
            "-\n",
            "Input sentence: It's hot.\n",
            "Decoded sentence:  To jest przerażające. _END\n",
            "-\n",
            "Input sentence: It's new.\n",
            "Decoded sentence:  To jest za duże. _END\n",
            "-\n",
            "Input sentence: It's red.\n",
            "Decoded sentence:  To jest przerażające. _END\n",
            "-\n",
            "Input sentence: It's red.\n",
            "Decoded sentence:  To jest przerażające. _END\n",
            "-\n",
            "Input sentence: It's red.\n",
            "Decoded sentence:  To jest przerażające. _END\n",
            "-\n",
            "Input sentence: Keep out!\n",
            "Decoded sentence:  Idź do mną. _END\n",
            "-\n",
            "Input sentence: Keep out.\n",
            "Decoded sentence:  Po proszę. _END\n",
            "-\n",
            "Input sentence: Kiss Tom.\n",
            "Decoded sentence:  Pocałuj Toma. _END\n",
            "-\n",
            "Input sentence: Leave it.\n",
            "Decoded sentence:  Weź to. _END\n",
            "-\n",
            "Input sentence: Leave me.\n",
            "Decoded sentence:  Chodź do mną. _END\n",
            "-\n",
            "Input sentence: Leave us.\n",
            "Decoded sentence:  Spróbuj w mną. _END\n",
            "-\n",
            "Input sentence: Let's go!\n",
            "Decoded sentence:  Jedz powoli. _END\n",
            "-\n",
            "Input sentence: Look out!\n",
            "Decoded sentence:  Usiądź do mną. _END\n",
            "-\n",
            "Input sentence: Marry me.\n",
            "Decoded sentence:  Przestań się śmiać. _END\n",
            "-\n",
            "Input sentence: May I go?\n",
            "Decoded sentence:  Kto cię kocha. _END\n",
            "-\n",
            "Input sentence: Save Tom.\n",
            "Decoded sentence:  Po Toma. _END\n",
            "-\n",
            "Input sentence: She runs.\n",
            "Decoded sentence:  Są dziwne. _END\n",
            "-\n",
            "Input sentence: Sit down!\n",
            "Decoded sentence:  Pomóż dzięki. _END\n",
            "-\n",
            "Input sentence: Sit down!\n",
            "Decoded sentence:  Pomóż dzięki. _END\n",
            "-\n",
            "Input sentence: Sit down.\n",
            "Decoded sentence:  Usiądź do domu. _END\n",
            "-\n",
            "Input sentence: Sit here.\n",
            "Decoded sentence:  Weź to. _END\n",
            "-\n",
            "Input sentence: Speak up!\n",
            "Decoded sentence:  Po proszę. _END\n",
            "-\n",
            "Input sentence: Stand by.\n",
            "Decoded sentence:  Idź na Tom'em. _END\n",
            "-\n",
            "Input sentence: Stand up!\n",
            "Decoded sentence:  Po i w w pobliżu. _END\n",
            "-\n",
            "Input sentence: Stay put.\n",
            "Decoded sentence:  Zostań w domu. _END\n",
            "-\n",
            "Input sentence: Stop Tom.\n",
            "Decoded sentence:  Zostań w domu. _END\n",
            "-\n",
            "Input sentence: Take Tom.\n",
            "Decoded sentence:  Weź Toma. _END\n",
            "-\n",
            "Input sentence: Tell Tom.\n",
            "Decoded sentence:  Bądź wstawaj. _END\n",
            "-\n",
            "Input sentence: Terrific!\n",
            "Decoded sentence:  Ptaki każdym razie dzięki. _END\n",
            "-\n",
            "Input sentence: They won.\n",
            "Decoded sentence:  Wesołych i wody. _END\n",
            "-\n",
            "Input sentence: Tom came.\n",
            "Decoded sentence:  Tom się na uśmiechnął. _END\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9Yl_HNi5DCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}