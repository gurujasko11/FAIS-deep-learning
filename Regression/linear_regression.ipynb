{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.text as text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ y_i = x_{ij} w_j + b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ y_i = x_{ij} w_j, \\quad x_{i,-1}=1,\\quad b=w_{-1} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def linear(x,w):\n",
    "    return x @ w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Generate a random feature vector $\\mathbf{x}$ witch 10000 samples and three feature \n",
    "such that first feature is drawn from N(0,1), second feature from  U(,1) and third from N(1,2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.stack((np.random.normal(0, 1, (1000)), \n",
    "              np.random.uniform(0, 1, (1000)), \n",
    "              np.random.normal(1,2, (1000))), axis=1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "N(mu,sigma) denotes normal distribution with mean mu and standard deviation sigma. You can use ``numpy.random.normal`` and ``numpy.random.uniform`` functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Using $\\mathbf{x}$ and weights w = [0.2, 0.5,-0.25,1.0] generate output $\\mathbf{y}$ assuming a $N(0,0.1)$ noise $\\mathbf{\\epsilon}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array((0.2, 0.5, -0.25, 1.))\n",
    "ones = np.ones((x.shape[0], 1))\n",
    "x = np.concatenate((x,ones), axis = 1)\n",
    "noise = np.random.normal(0, 0.1)\n",
    "y = linear(x,w)\n",
    "y = y + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "$$ y_i = x_{ij} w_j+\\epsilon_i, \\quad x_{i,-1}=1,\\quad b=w_{-1} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ \\frac{1}{2}\\frac{1}{N}\\sum_{i=0}^{N-1} (y_i -  x_{ij} w_j  )^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLoss(y, x, w):\n",
    "    loss = np.square(y - linear(x,w))\n",
    "    loss = np.sum(loss) / (2*y.shape[0])\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the gradient of the loss function with respect to weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write gradient function ``grad(y,x,w)``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00015544 -0.00385066 -0.00709402 -0.00766448]\n"
     ]
    }
   ],
   "source": [
    "def grad(y, x, w):\n",
    "    diff = (x @ w - y)\n",
    "    return np.dot(x.T, diff) / x.shape[0]\n",
    "#     return (w - (alpha/x.shape[0]) * tmp)\n",
    "gradient = grad(y, x, w)\n",
    "print(gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement gradient descent for linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished gradient descent on iteration 113\n",
      "with loss equal 9.966835550193213e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.19998102,  0.50151607, -0.24998489,  1.00683376])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.1\n",
    "\n",
    "def gradientDescent(y, x, w, maxIterations = 500, tolerance=0.0000001):\n",
    "    for i in range(maxIterations):\n",
    "        loss = getLoss(y, x, w)\n",
    "        if loss < tolerance:\n",
    "            maxIterations = i\n",
    "            break\n",
    "        gradient = grad(y, x, w)\n",
    "        w = w - alpha*gradient\n",
    "\n",
    "    print(\"finished gradient descent on iteration \" + str(maxIterations))\n",
    "    print(\"with loss equal \" + str(loss))\n",
    "    return w\n",
    "        \n",
    "gradientDescent(y, x, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement stochastic gradient descent (SGD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished gradient descent on iteration 111\n",
      "with loss equal 9.968142672278636e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.20002494,  0.50152032, -0.24999132,  1.00686708])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getBatches(x, y, batchSize):\n",
    "    randomIndices = np.random.randint(1000, size=(batchSize))\n",
    "    xResult = []\n",
    "    yResult = []\n",
    "    for i in randomIndices:\n",
    "        xResult.append(x[i])\n",
    "        yResult.append(y[i])\n",
    "    return (np.asanyarray(xResult), np.asanyarray(yResult))\n",
    "\n",
    "def sgd(y, x, w, maxIterations = 500, tolerance=0.0000001, batchSize = 10):\n",
    "    for i in range(maxIterations):\n",
    "        loss = getLoss(y, x, w)\n",
    "        if loss < tolerance:\n",
    "            maxIterations = i\n",
    "            break\n",
    "        randomIndices = np.random.randint(1000, size=(batchSize))\n",
    "        selectedX = x[randomIndices]\n",
    "        selectedY = y[randomIndices]\n",
    "#         (selectedX, selectedY) = getBatches(x, y, batchSize)\n",
    "        gradient = grad(selectedY, selectedX, w)\n",
    "        w = w - alpha*gradient\n",
    "\n",
    "    print(\"finished gradient descent on iteration \" + str(maxIterations))\n",
    "    print(\"with loss equal \" + str(loss))\n",
    "    return w\n",
    "sgd(y, x, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD takes: \n",
      "finished gradient descent on iteration 124\n",
      "with loss equal 9.865369386331472e-08\n",
      "CPU times: user 9.46 ms, sys: 450 Âµs, total: 9.91 ms\n",
      "Wall time: 9.02 ms\n",
      "gradient descent takes: \n",
      "finished gradient descent on iteration 113\n",
      "with loss equal 9.966835550193213e-08\n",
      "CPU times: user 6.34 ms, sys: 0 ns, total: 6.34 ms\n",
      "Wall time: 6.17 ms\n"
     ]
    }
   ],
   "source": [
    "print(\"SGD takes: \")\n",
    "%time tSGD = sgd(y, x, w)\n",
    "print(\"gradient descent takes: \")\n",
    "%time tGD = gradientDescent(y, x, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement SGD using pytorch. Start by just rewritting Problem 3 to use torch Tensors instead of numpy arrays. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert frrom numpy arrays to torch tensors you can use ``torch.from_numpy()`` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2903,  0.0101,  1.7262,  1.0000],\n",
      "        [ 0.5182,  0.8843,  1.4876,  1.0000],\n",
      "        [ 0.0453,  0.6313,  1.0153,  1.0000],\n",
      "        ...,\n",
      "        [-1.4175,  0.0063,  0.1106,  1.0000],\n",
      "        [ 0.7033,  0.4105,  0.7287,  1.0000],\n",
      "        [ 1.2382,  0.8392,  4.9640,  1.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchviz import make_dot\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "x_train_tensor = torch.from_numpy(x).float().to(device)\n",
    "y_train_tensor = torch.from_numpy(y).float().to(device)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(x_train_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelTorch(x):\n",
    "    return x @ w.t() + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(inf, grad_fn=<RsubBackward1>)\n",
      "tensor(34612736., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(5133116., grad_fn=<SubBackward0>)\n",
      "tensor(29479620., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(4219604., grad_fn=<SubBackward0>)\n",
      "tensor(25260016., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3475624., grad_fn=<SubBackward0>)\n",
      "tensor(21784392., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2869400., grad_fn=<SubBackward0>)\n",
      "tensor(18914992., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2375178., grad_fn=<SubBackward0>)\n",
      "tensor(16539814., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1972004., grad_fn=<SubBackward0>)\n",
      "tensor(14567810., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1642852., grad_fn=<SubBackward0>)\n",
      "tensor(12924958., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1373906., grad_fn=<SubBackward0>)\n",
      "tensor(11551052., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1153926., grad_fn=<SubBackward0>)\n",
      "tensor(10397126., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(973774., grad_fn=<SubBackward0>)\n",
      "tensor(9423352., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(826046., grad_fn=<SubBackward0>)\n",
      "tensor(8597306., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(704703., grad_fn=<SubBackward0>)\n",
      "tensor(7892603., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(604846., grad_fn=<SubBackward0>)\n",
      "tensor(7287757., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(522494.5000, grad_fn=<SubBackward0>)\n",
      "tensor(6765262.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(454410.5000, grad_fn=<SubBackward0>)\n",
      "tensor(6310852., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(397962., grad_fn=<SubBackward0>)\n",
      "tensor(5912890., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(351005., grad_fn=<SubBackward0>)\n",
      "tensor(5561885., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(311810., grad_fn=<SubBackward0>)\n",
      "tensor(5250075., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(278955., grad_fn=<SubBackward0>)\n",
      "tensor(4971120., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(251285., grad_fn=<SubBackward0>)\n",
      "tensor(4719835., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(227873., grad_fn=<SubBackward0>)\n",
      "tensor(4491962., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(207948., grad_fn=<SubBackward0>)\n",
      "tensor(4284014., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(190895., grad_fn=<SubBackward0>)\n",
      "tensor(4093119., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(176205., grad_fn=<SubBackward0>)\n",
      "tensor(3916914., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(163472., grad_fn=<SubBackward0>)\n",
      "tensor(3753442., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(152352.5000, grad_fn=<SubBackward0>)\n",
      "tensor(3601089.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(142578., grad_fn=<SubBackward0>)\n",
      "tensor(3458511.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(133919.5000, grad_fn=<SubBackward0>)\n",
      "tensor(3324592., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(126200.5000, grad_fn=<SubBackward0>)\n",
      "tensor(3198391.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(119266.5000, grad_fn=<SubBackward0>)\n",
      "tensor(3079125., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(112997.2500, grad_fn=<SubBackward0>)\n",
      "tensor(2966127.7500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(107292.5000, grad_fn=<SubBackward0>)\n",
      "tensor(2858835.2500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(102069., grad_fn=<SubBackward0>)\n",
      "tensor(2756766.2500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(97257.7500, grad_fn=<SubBackward0>)\n",
      "tensor(2659508.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(92806.5000, grad_fn=<SubBackward0>)\n",
      "tensor(2566702., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(88665.5000, grad_fn=<SubBackward0>)\n",
      "tensor(2478036.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(84796., grad_fn=<SubBackward0>)\n",
      "tensor(2393240.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(81167.2500, grad_fn=<SubBackward0>)\n",
      "tensor(2312073.2500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(77754.7500, grad_fn=<SubBackward0>)\n",
      "tensor(2234318.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(74531., grad_fn=<SubBackward0>)\n",
      "tensor(2159787.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(71480.6250, grad_fn=<SubBackward0>)\n",
      "tensor(2088306.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(68588.2500, grad_fn=<SubBackward0>)\n",
      "tensor(2019718.6250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(65837.8750, grad_fn=<SubBackward0>)\n",
      "tensor(1953880.7500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(63219.5000, grad_fn=<SubBackward0>)\n",
      "tensor(1890661.2500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(60721.5000, grad_fn=<SubBackward0>)\n",
      "tensor(1829939.7500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(58337.7500, grad_fn=<SubBackward0>)\n",
      "tensor(1771602., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(56058.1250, grad_fn=<SubBackward0>)\n",
      "tensor(1715543.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(53877.1250, grad_fn=<SubBackward0>)\n",
      "tensor(1661666.7500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(51788.5000, grad_fn=<SubBackward0>)\n",
      "tensor(1609878.2500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(49786.6250, grad_fn=<SubBackward0>)\n",
      "tensor(1560091.6250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(47868.1250, grad_fn=<SubBackward0>)\n",
      "tensor(1512223.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(46025.8750, grad_fn=<SubBackward0>)\n",
      "tensor(1466197.6250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(44259.8750, grad_fn=<SubBackward0>)\n",
      "tensor(1421937.7500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(42563., grad_fn=<SubBackward0>)\n",
      "tensor(1379374.7500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(40934., grad_fn=<SubBackward0>)\n",
      "tensor(1338440.7500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(39369.2500, grad_fn=<SubBackward0>)\n",
      "tensor(1299071.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(37864.7500, grad_fn=<SubBackward0>)\n",
      "tensor(1261206.7500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(36420.3750, grad_fn=<SubBackward0>)\n",
      "tensor(1224786.3750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(35030.7500, grad_fn=<SubBackward0>)\n",
      "tensor(1189755.6250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(33696.1250, grad_fn=<SubBackward0>)\n",
      "tensor(1156059.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(32411.7500, grad_fn=<SubBackward0>)\n",
      "tensor(1123647.7500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(31177.2500, grad_fn=<SubBackward0>)\n",
      "tensor(1092470.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(29991.1250, grad_fn=<SubBackward0>)\n",
      "tensor(1062479.3750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(28849.5000, grad_fn=<SubBackward0>)\n",
      "tensor(1033629.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(27752.3750, grad_fn=<SubBackward0>)\n",
      "tensor(1005877.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(26696.6250, grad_fn=<SubBackward0>)\n",
      "tensor(979180.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(25681.1250, grad_fn=<SubBackward0>)\n",
      "tensor(953499.7500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(24704.6250, grad_fn=<SubBackward0>)\n",
      "tensor(928795.1250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(23765.5625, grad_fn=<SubBackward0>)\n",
      "tensor(905029.5625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(22862.0625, grad_fn=<SubBackward0>)\n",
      "tensor(882167.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(21993.1250, grad_fn=<SubBackward0>)\n",
      "tensor(860174.3750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(21157.4375, grad_fn=<SubBackward0>)\n",
      "tensor(839016.9375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(20352.9375, grad_fn=<SubBackward0>)\n",
      "tensor(818664., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(19580.1875, grad_fn=<SubBackward0>)\n",
      "tensor(799083.8125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(18835.7500, grad_fn=<SubBackward0>)\n",
      "tensor(780248.0625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(18119.8750, grad_fn=<SubBackward0>)\n",
      "tensor(762128.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(17432., grad_fn=<SubBackward0>)\n",
      "tensor(744696.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(16769.5625, grad_fn=<SubBackward0>)\n",
      "tensor(727926.6250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(16132.5625, grad_fn=<SubBackward0>)\n",
      "tensor(711794.0625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(15519.6250, grad_fn=<SubBackward0>)\n",
      "tensor(696274.4375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(14930.1875, grad_fn=<SubBackward0>)\n",
      "tensor(681344.2500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(14363.2500, grad_fn=<SubBackward0>)\n",
      "tensor(666981., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(13816.8750, grad_fn=<SubBackward0>)\n",
      "tensor(653164.1250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(13292.8750, grad_fn=<SubBackward0>)\n",
      "tensor(639871.2500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(12787.7500, grad_fn=<SubBackward0>)\n",
      "tensor(627083.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(12301.7500, grad_fn=<SubBackward0>)\n",
      "tensor(614781.7500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(11834.7500, grad_fn=<SubBackward0>)\n",
      "tensor(602947., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(11384.9375, grad_fn=<SubBackward0>)\n",
      "tensor(591562.0625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(10953.3125, grad_fn=<SubBackward0>)\n",
      "tensor(580608.7500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(10536.8750, grad_fn=<SubBackward0>)\n",
      "tensor(570071.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(10136.7500, grad_fn=<SubBackward0>)\n",
      "tensor(559935.1250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(9752.1250, grad_fn=<SubBackward0>)\n",
      "tensor(550183., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(9381.2500, grad_fn=<SubBackward0>)\n",
      "tensor(540801.7500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(9025.5000, grad_fn=<SubBackward0>)\n",
      "tensor(531776.2500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(8682.6875, grad_fn=<SubBackward0>)\n",
      "tensor(523093.5625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(8353.0625, grad_fn=<SubBackward0>)\n",
      "tensor(514740.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(8035.5625, grad_fn=<SubBackward0>)\n",
      "tensor(506704.9375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(7730.6250, grad_fn=<SubBackward0>)\n",
      "tensor(498974.3125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(7437.1562, grad_fn=<SubBackward0>)\n",
      "tensor(491537.1562, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(7154.6562, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(484382.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(6883.3125, grad_fn=<SubBackward0>)\n",
      "tensor(477499.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(6621.9062, grad_fn=<SubBackward0>)\n",
      "tensor(470877.2812, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(6370.5312, grad_fn=<SubBackward0>)\n",
      "tensor(464506.7500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(6128.5625, grad_fn=<SubBackward0>)\n",
      "tensor(458378.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(5896., grad_fn=<SubBackward0>)\n",
      "tensor(452482.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(5672., grad_fn=<SubBackward0>)\n",
      "tensor(446810.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(5457.0312, grad_fn=<SubBackward0>)\n",
      "tensor(441353.1562, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(5249.6562, grad_fn=<SubBackward0>)\n",
      "tensor(436103.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(5050.6250, grad_fn=<SubBackward0>)\n",
      "tensor(431052.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(4858.9688, grad_fn=<SubBackward0>)\n",
      "tensor(426193.9062, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(4674.0938, grad_fn=<SubBackward0>)\n",
      "tensor(421519.8125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(4497.1875, grad_fn=<SubBackward0>)\n",
      "tensor(417022.6250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(4326.4062, grad_fn=<SubBackward0>)\n",
      "tensor(412696.2188, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(4162.1562, grad_fn=<SubBackward0>)\n",
      "tensor(408534.0625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(4004.3750, grad_fn=<SubBackward0>)\n",
      "tensor(404529.6875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3852.2500, grad_fn=<SubBackward0>)\n",
      "tensor(400677.4375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3706.1562, grad_fn=<SubBackward0>)\n",
      "tensor(396971.2812, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3565.6250, grad_fn=<SubBackward0>)\n",
      "tensor(393405.6562, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3430.2812, grad_fn=<SubBackward0>)\n",
      "tensor(389975.3750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3300.1875, grad_fn=<SubBackward0>)\n",
      "tensor(386675.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3175.0625, grad_fn=<SubBackward0>)\n",
      "tensor(383500.1250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3054.5312, grad_fn=<SubBackward0>)\n",
      "tensor(380445.5938, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2938.7500, grad_fn=<SubBackward0>)\n",
      "tensor(377506.8438, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2827.1562, grad_fn=<SubBackward0>)\n",
      "tensor(374679.6875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2719.9688, grad_fn=<SubBackward0>)\n",
      "tensor(371959.7188, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2616.8438, grad_fn=<SubBackward0>)\n",
      "tensor(369342.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2517.5625, grad_fn=<SubBackward0>)\n",
      "tensor(366825.3125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2422.1875, grad_fn=<SubBackward0>)\n",
      "tensor(364403.1250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2330.3125, grad_fn=<SubBackward0>)\n",
      "tensor(362072.8125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2242.0625, grad_fn=<SubBackward0>)\n",
      "tensor(359830.7500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2156.9375, grad_fn=<SubBackward0>)\n",
      "tensor(357673.8125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2075.2188, grad_fn=<SubBackward0>)\n",
      "tensor(355598.5938, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1996.5312, grad_fn=<SubBackward0>)\n",
      "tensor(353602.0625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1920.8750, grad_fn=<SubBackward0>)\n",
      "tensor(351681.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1848.2500, grad_fn=<SubBackward0>)\n",
      "tensor(349832.9375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1777.9375, grad_fn=<SubBackward0>)\n",
      "tensor(348055., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1710.6875, grad_fn=<SubBackward0>)\n",
      "tensor(346344.3125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1645.9375, grad_fn=<SubBackward0>)\n",
      "tensor(344698.3750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1583.5000, grad_fn=<SubBackward0>)\n",
      "tensor(343114.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1523.5000, grad_fn=<SubBackward0>)\n",
      "tensor(341591.3750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1465.8750, grad_fn=<SubBackward0>)\n",
      "tensor(340125.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1410.1250, grad_fn=<SubBackward0>)\n",
      "tensor(338715.3750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1357.0625, grad_fn=<SubBackward0>)\n",
      "tensor(337358.3125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1305.4375, grad_fn=<SubBackward0>)\n",
      "tensor(336052.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1256.1250, grad_fn=<SubBackward0>)\n",
      "tensor(334796.7500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1208.5000, grad_fn=<SubBackward0>)\n",
      "tensor(333588.2500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1162.8438, grad_fn=<SubBackward0>)\n",
      "tensor(332425.4062, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1118.6562, grad_fn=<SubBackward0>)\n",
      "tensor(331306.7500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1076.4375, grad_fn=<SubBackward0>)\n",
      "tensor(330230.3125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1035.7812, grad_fn=<SubBackward0>)\n",
      "tensor(329194.5312, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(996.6562, grad_fn=<SubBackward0>)\n",
      "tensor(328197.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(958.6875, grad_fn=<SubBackward0>)\n",
      "tensor(327239.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(922.8438, grad_fn=<SubBackward0>)\n",
      "tensor(326316.3438, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(887.5938, grad_fn=<SubBackward0>)\n",
      "tensor(325428.7500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(854.0938, grad_fn=<SubBackward0>)\n",
      "tensor(324574.6562, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(821.7812, grad_fn=<SubBackward0>)\n",
      "tensor(323752.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(790.9375, grad_fn=<SubBackward0>)\n",
      "tensor(322961.9375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(760.8750, grad_fn=<SubBackward0>)\n",
      "tensor(322201.0625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(732.1562, grad_fn=<SubBackward0>)\n",
      "tensor(321468.9062, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(704.4062, grad_fn=<SubBackward0>)\n",
      "tensor(320764.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(677.8125, grad_fn=<SubBackward0>)\n",
      "tensor(320086.6875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(652.5625, grad_fn=<SubBackward0>)\n",
      "tensor(319434.1250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(627.5312, grad_fn=<SubBackward0>)\n",
      "tensor(318806.5938, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(603.9062, grad_fn=<SubBackward0>)\n",
      "tensor(318202.6875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(581.2188, grad_fn=<SubBackward0>)\n",
      "tensor(317621.4688, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(559.2812, grad_fn=<SubBackward0>)\n",
      "tensor(317062.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(538.0625, grad_fn=<SubBackward0>)\n",
      "tensor(316524.1250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(517.8750, grad_fn=<SubBackward0>)\n",
      "tensor(316006.2500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(498.5000, grad_fn=<SubBackward0>)\n",
      "tensor(315507.7500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(479.6875, grad_fn=<SubBackward0>)\n",
      "tensor(315028.0625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(461.3750, grad_fn=<SubBackward0>)\n",
      "tensor(314566.6875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(444.1250, grad_fn=<SubBackward0>)\n",
      "tensor(314122.5625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(427.3750, grad_fn=<SubBackward0>)\n",
      "tensor(313695.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(411.1875, grad_fn=<SubBackward0>)\n",
      "tensor(313284., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(395.9375, grad_fn=<SubBackward0>)\n",
      "tensor(312888.0625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(381., grad_fn=<SubBackward0>)\n",
      "tensor(312507.0625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(366.4375, grad_fn=<SubBackward0>)\n",
      "tensor(312140.6250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(352.9688, grad_fn=<SubBackward0>)\n",
      "tensor(311787.6562, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(339.4062, grad_fn=<SubBackward0>)\n",
      "tensor(311448.2500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(327., grad_fn=<SubBackward0>)\n",
      "tensor(311121.2500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(314.3125, grad_fn=<SubBackward0>)\n",
      "tensor(310806.9375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(302.8125, grad_fn=<SubBackward0>)\n",
      "tensor(310504.1250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(291.4688, grad_fn=<SubBackward0>)\n",
      "tensor(310212.6562, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(280.3438, grad_fn=<SubBackward0>)\n",
      "tensor(309932.3125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(270.0625, grad_fn=<SubBackward0>)\n",
      "tensor(309662.2500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(259.6875, grad_fn=<SubBackward0>)\n",
      "tensor(309402.5625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(250.1875, grad_fn=<SubBackward0>)\n",
      "tensor(309152.3750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(240.6250, grad_fn=<SubBackward0>)\n",
      "tensor(308911.7500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(231.7500, grad_fn=<SubBackward0>)\n",
      "tensor(308680., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(223.0625, grad_fn=<SubBackward0>)\n",
      "tensor(308456.9375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(214.8125, grad_fn=<SubBackward0>)\n",
      "tensor(308242.1250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(206.5625, grad_fn=<SubBackward0>)\n",
      "tensor(308035.5625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(199.1250, grad_fn=<SubBackward0>)\n",
      "tensor(307836.4375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(191.5625, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(307644.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(184.4375, grad_fn=<SubBackward0>)\n",
      "tensor(307460.4375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(177.5000, grad_fn=<SubBackward0>)\n",
      "tensor(307282.9375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(171.0625, grad_fn=<SubBackward0>)\n",
      "tensor(307111.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(164.5000, grad_fn=<SubBackward0>)\n",
      "tensor(306947.3750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(158.5000, grad_fn=<SubBackward0>)\n",
      "tensor(306788.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(152.5000, grad_fn=<SubBackward0>)\n",
      "tensor(306636.3750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(146.9688, grad_fn=<SubBackward0>)\n",
      "tensor(306489.4062, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(141.4688, grad_fn=<SubBackward0>)\n",
      "tensor(306347.9375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(136.2188, grad_fn=<SubBackward0>)\n",
      "tensor(306211.7188, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(131.1562, grad_fn=<SubBackward0>)\n",
      "tensor(306080.5625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(126.3125, grad_fn=<SubBackward0>)\n",
      "tensor(305954.2500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(121.7188, grad_fn=<SubBackward0>)\n",
      "tensor(305832.5312, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(117.1250, grad_fn=<SubBackward0>)\n",
      "tensor(305715.4062, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(113., grad_fn=<SubBackward0>)\n",
      "tensor(305602.4062, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(108.5938, grad_fn=<SubBackward0>)\n",
      "tensor(305493.8125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(104.6875, grad_fn=<SubBackward0>)\n",
      "tensor(305389.1250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(100.8125, grad_fn=<SubBackward0>)\n",
      "tensor(305288.3125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(97.1875, grad_fn=<SubBackward0>)\n",
      "tensor(305191.1250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(93.5938, grad_fn=<SubBackward0>)\n",
      "tensor(305097.5312, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(90.0938, grad_fn=<SubBackward0>)\n",
      "tensor(305007.4375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(86.8750, grad_fn=<SubBackward0>)\n",
      "tensor(304920.5625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(83.6875, grad_fn=<SubBackward0>)\n",
      "tensor(304836.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(80.6875, grad_fn=<SubBackward0>)\n",
      "tensor(304756.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(77.5938, grad_fn=<SubBackward0>)\n",
      "tensor(304678.5938, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(74.6562, grad_fn=<SubBackward0>)\n",
      "tensor(304603.9375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(72.3125, grad_fn=<SubBackward0>)\n",
      "tensor(304531.6250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(69.5312, grad_fn=<SubBackward0>)\n",
      "tensor(304462.0938, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(67.0312, grad_fn=<SubBackward0>)\n",
      "tensor(304395.0625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(64.5000, grad_fn=<SubBackward0>)\n",
      "tensor(304330.5625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(62.3125, grad_fn=<SubBackward0>)\n",
      "tensor(304268.2500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(59.9375, grad_fn=<SubBackward0>)\n",
      "tensor(304208.3125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(57.9375, grad_fn=<SubBackward0>)\n",
      "tensor(304150.3750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(55.8750, grad_fn=<SubBackward0>)\n",
      "tensor(304094.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(53.6250, grad_fn=<SubBackward0>)\n",
      "tensor(304040.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(51.9062, grad_fn=<SubBackward0>)\n",
      "tensor(303988.9688, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(50.0625, grad_fn=<SubBackward0>)\n",
      "tensor(303938.9062, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(48.1875, grad_fn=<SubBackward0>)\n",
      "tensor(303890.7188, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(46.5312, grad_fn=<SubBackward0>)\n",
      "tensor(303844.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(44.9375, grad_fn=<SubBackward0>)\n",
      "tensor(303799.2500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(43.1250, grad_fn=<SubBackward0>)\n",
      "tensor(303756.1250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(41.9375, grad_fn=<SubBackward0>)\n",
      "tensor(303714.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(40.2500, grad_fn=<SubBackward0>)\n",
      "tensor(303673.9375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(38.8438, grad_fn=<SubBackward0>)\n",
      "tensor(303635.0938, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(37.5625, grad_fn=<SubBackward0>)\n",
      "tensor(303597.5312, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(36.1562, grad_fn=<SubBackward0>)\n",
      "tensor(303561.3750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(35.0625, grad_fn=<SubBackward0>)\n",
      "tensor(303526.3125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(33.6250, grad_fn=<SubBackward0>)\n",
      "tensor(303492.6875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(32.5000, grad_fn=<SubBackward0>)\n",
      "tensor(303460.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(31.5000, grad_fn=<SubBackward0>)\n",
      "tensor(303428.6875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(30.5000, grad_fn=<SubBackward0>)\n",
      "tensor(303398.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(29.3125, grad_fn=<SubBackward0>)\n",
      "tensor(303368.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(28.4375, grad_fn=<SubBackward0>)\n",
      "tensor(303340.4375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(27.2500, grad_fn=<SubBackward0>)\n",
      "tensor(303313.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(26.3125, grad_fn=<SubBackward0>)\n",
      "tensor(303286.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(25.6875, grad_fn=<SubBackward0>)\n",
      "tensor(303261.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(24.7500, grad_fn=<SubBackward0>)\n",
      "tensor(303236.4375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(23.8750, grad_fn=<SubBackward0>)\n",
      "tensor(303212.5625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(22.9688, grad_fn=<SubBackward0>)\n",
      "tensor(303189.5938, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(22.3438, grad_fn=<SubBackward0>)\n",
      "tensor(303167.2500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(21.5938, grad_fn=<SubBackward0>)\n",
      "tensor(303145.6562, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(21., grad_fn=<SubBackward0>)\n",
      "tensor(303124.6562, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(20.1562, grad_fn=<SubBackward0>)\n",
      "tensor(303104.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(19.5625, grad_fn=<SubBackward0>)\n",
      "tensor(303084.9375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(18.8125, grad_fn=<SubBackward0>)\n",
      "tensor(303066.1250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(18.3438, grad_fn=<SubBackward0>)\n",
      "tensor(303047.7812, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(17.8125, grad_fn=<SubBackward0>)\n",
      "tensor(303029.9688, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(16.9062, grad_fn=<SubBackward0>)\n",
      "tensor(303013.0625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(16.6875, grad_fn=<SubBackward0>)\n",
      "tensor(302996.3750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(16.1875, grad_fn=<SubBackward0>)\n",
      "tensor(302980.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(15.5312, grad_fn=<SubBackward0>)\n",
      "tensor(302964.6562, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(15.3125, grad_fn=<SubBackward0>)\n",
      "tensor(302949.3438, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(14.4688, grad_fn=<SubBackward0>)\n",
      "tensor(302934.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(14.2812, grad_fn=<SubBackward0>)\n",
      "tensor(302920.5938, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(13.5312, grad_fn=<SubBackward0>)\n",
      "tensor(302907.0625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(13.4375, grad_fn=<SubBackward0>)\n",
      "tensor(302893.6250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(13., grad_fn=<SubBackward0>)\n",
      "tensor(302880.6250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(12.5000, grad_fn=<SubBackward0>)\n",
      "tensor(302868.1250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(12.1875, grad_fn=<SubBackward0>)\n",
      "tensor(302855.9375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(11.8438, grad_fn=<SubBackward0>)\n",
      "tensor(302844.0938, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(11.4688, grad_fn=<SubBackward0>)\n",
      "tensor(302832.6250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(11.1875, grad_fn=<SubBackward0>)\n",
      "tensor(302821.4375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(10.8750, grad_fn=<SubBackward0>)\n",
      "tensor(302810.5625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(10.5625, grad_fn=<SubBackward0>)\n",
      "tensor(302800., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(10.3125, grad_fn=<SubBackward0>)\n",
      "tensor(302789.6875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(9.8125, grad_fn=<SubBackward0>)\n",
      "tensor(302779.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(9.8125, grad_fn=<SubBackward0>)\n",
      "tensor(302770.0625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(9.3750, grad_fn=<SubBackward0>)\n",
      "tensor(302760.6875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(9.1875, grad_fn=<SubBackward0>)\n",
      "tensor(302751.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(8.7500, grad_fn=<SubBackward0>)\n",
      "tensor(302742.7500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(8.7188, grad_fn=<SubBackward0>)\n",
      "tensor(302734.0312, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(8.5312, grad_fn=<SubBackward0>)\n",
      "tensor(302725.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(8.2500, grad_fn=<SubBackward0>)\n",
      "tensor(302717.2500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(7.8750, grad_fn=<SubBackward0>)\n",
      "tensor(302709.3750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(7.9688, grad_fn=<SubBackward0>)\n",
      "tensor(302701.4062, grad_fn=<SumBackward0>)\n",
      "--------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.7188, grad_fn=<SubBackward0>)\n",
      "tensor(302693.6875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(7.3125, grad_fn=<SubBackward0>)\n",
      "tensor(302686.3750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(7.2500, grad_fn=<SubBackward0>)\n",
      "tensor(302679.1250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(7.1250, grad_fn=<SubBackward0>)\n",
      "tensor(302672., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(6.9688, grad_fn=<SubBackward0>)\n",
      "tensor(302665.0312, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(6.7188, grad_fn=<SubBackward0>)\n",
      "tensor(302658.3125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(6.6562, grad_fn=<SubBackward0>)\n",
      "tensor(302651.6562, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(6.4688, grad_fn=<SubBackward0>)\n",
      "tensor(302645.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(6.3125, grad_fn=<SubBackward0>)\n",
      "tensor(302638.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(6.0625, grad_fn=<SubBackward0>)\n",
      "tensor(302632.8125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(6.0625, grad_fn=<SubBackward0>)\n",
      "tensor(302626.7500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(5.8750, grad_fn=<SubBackward0>)\n",
      "tensor(302620.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(5.8125, grad_fn=<SubBackward0>)\n",
      "tensor(302615.0625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(5.6250, grad_fn=<SubBackward0>)\n",
      "tensor(302609.4375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(5.5625, grad_fn=<SubBackward0>)\n",
      "tensor(302603.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(5.4688, grad_fn=<SubBackward0>)\n",
      "tensor(302598.4062, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(5.2500, grad_fn=<SubBackward0>)\n",
      "tensor(302593.1562, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(5.2188, grad_fn=<SubBackward0>)\n",
      "tensor(302587.9375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(5., grad_fn=<SubBackward0>)\n",
      "tensor(302582.9375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(5., grad_fn=<SubBackward0>)\n",
      "tensor(302577.9375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(4.9375, grad_fn=<SubBackward0>)\n",
      "tensor(302573., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(4.8750, grad_fn=<SubBackward0>)\n",
      "tensor(302568.1250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(4.7188, grad_fn=<SubBackward0>)\n",
      "tensor(302563.4062, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(4.6875, grad_fn=<SubBackward0>)\n",
      "tensor(302558.7188, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(4.5312, grad_fn=<SubBackward0>)\n",
      "tensor(302554.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(4.5625, grad_fn=<SubBackward0>)\n",
      "tensor(302549.6250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(4.4375, grad_fn=<SubBackward0>)\n",
      "tensor(302545.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(4.3125, grad_fn=<SubBackward0>)\n",
      "tensor(302540.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(4.3438, grad_fn=<SubBackward0>)\n",
      "tensor(302536.5312, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(4.2188, grad_fn=<SubBackward0>)\n",
      "tensor(302532.3125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(4.1250, grad_fn=<SubBackward0>)\n",
      "tensor(302528.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(4., grad_fn=<SubBackward0>)\n",
      "tensor(302524.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(4., grad_fn=<SubBackward0>)\n",
      "tensor(302520.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(4.0625, grad_fn=<SubBackward0>)\n",
      "tensor(302516.1250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3.7500, grad_fn=<SubBackward0>)\n",
      "tensor(302512.3750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(4., grad_fn=<SubBackward0>)\n",
      "tensor(302508.3750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3.7500, grad_fn=<SubBackward0>)\n",
      "tensor(302504.6250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3.7188, grad_fn=<SubBackward0>)\n",
      "tensor(302500.9062, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3.5938, grad_fn=<SubBackward0>)\n",
      "tensor(302497.3125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3.6250, grad_fn=<SubBackward0>)\n",
      "tensor(302493.6875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3.6250, grad_fn=<SubBackward0>)\n",
      "tensor(302490.0625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3.5000, grad_fn=<SubBackward0>)\n",
      "tensor(302486.5625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3.6250, grad_fn=<SubBackward0>)\n",
      "tensor(302482.9375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3.3750, grad_fn=<SubBackward0>)\n",
      "tensor(302479.5625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3.3750, grad_fn=<SubBackward0>)\n",
      "tensor(302476.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3.3438, grad_fn=<SubBackward0>)\n",
      "tensor(302472.8438, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3.2812, grad_fn=<SubBackward0>)\n",
      "tensor(302469.5625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3.3750, grad_fn=<SubBackward0>)\n",
      "tensor(302466.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3.3750, grad_fn=<SubBackward0>)\n",
      "tensor(302462.8125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3.1875, grad_fn=<SubBackward0>)\n",
      "tensor(302459.6250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3.2500, grad_fn=<SubBackward0>)\n",
      "tensor(302456.3750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3.1250, grad_fn=<SubBackward0>)\n",
      "tensor(302453.2500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3.1875, grad_fn=<SubBackward0>)\n",
      "tensor(302450.0625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3.1250, grad_fn=<SubBackward0>)\n",
      "tensor(302446.9375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3., grad_fn=<SubBackward0>)\n",
      "tensor(302443.9375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3.0625, grad_fn=<SubBackward0>)\n",
      "tensor(302440.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3., grad_fn=<SubBackward0>)\n",
      "tensor(302437.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3.0312, grad_fn=<SubBackward0>)\n",
      "tensor(302434.8438, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.9688, grad_fn=<SubBackward0>)\n",
      "tensor(302431.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.9375, grad_fn=<SubBackward0>)\n",
      "tensor(302428.9375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.8750, grad_fn=<SubBackward0>)\n",
      "tensor(302426.0625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.9375, grad_fn=<SubBackward0>)\n",
      "tensor(302423.1250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.7500, grad_fn=<SubBackward0>)\n",
      "tensor(302420.3750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(3., grad_fn=<SubBackward0>)\n",
      "tensor(302417.3750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.6875, grad_fn=<SubBackward0>)\n",
      "tensor(302414.6875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.7500, grad_fn=<SubBackward0>)\n",
      "tensor(302411.9375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.8750, grad_fn=<SubBackward0>)\n",
      "tensor(302409.0625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.7812, grad_fn=<SubBackward0>)\n",
      "tensor(302406.2812, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.7188, grad_fn=<SubBackward0>)\n",
      "tensor(302403.5625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.8750, grad_fn=<SubBackward0>)\n",
      "tensor(302400.6875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.5625, grad_fn=<SubBackward0>)\n",
      "tensor(302398.1250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.7188, grad_fn=<SubBackward0>)\n",
      "tensor(302395.4062, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.6562, grad_fn=<SubBackward0>)\n",
      "tensor(302392.7500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.6250, grad_fn=<SubBackward0>)\n",
      "tensor(302390.1250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.6875, grad_fn=<SubBackward0>)\n",
      "tensor(302387.4375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.5625, grad_fn=<SubBackward0>)\n",
      "tensor(302384.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.5000, grad_fn=<SubBackward0>)\n",
      "tensor(302382.3750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.6562, grad_fn=<SubBackward0>)\n",
      "tensor(302379.7188, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.5312, grad_fn=<SubBackward0>)\n",
      "tensor(302377.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.6250, grad_fn=<SubBackward0>)\n",
      "tensor(302374.5625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.4375, grad_fn=<SubBackward0>)\n",
      "tensor(302372.1250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.6875, grad_fn=<SubBackward0>)\n",
      "tensor(302369.4375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.5625, grad_fn=<SubBackward0>)\n",
      "tensor(302366.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.3750, grad_fn=<SubBackward0>)\n",
      "tensor(302364.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.4062, grad_fn=<SubBackward0>)\n",
      "tensor(302362.0938, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.4688, grad_fn=<SubBackward0>)\n",
      "tensor(302359.6250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.4688, grad_fn=<SubBackward0>)\n",
      "tensor(302357.1562, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.3438, grad_fn=<SubBackward0>)\n",
      "tensor(302354.8125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.4062, grad_fn=<SubBackward0>)\n",
      "tensor(302352.4062, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.4062, grad_fn=<SubBackward0>)\n",
      "tensor(302350., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.4375, grad_fn=<SubBackward0>)\n",
      "tensor(302347.5625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.3125, grad_fn=<SubBackward0>)\n",
      "tensor(302345.2500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.3750, grad_fn=<SubBackward0>)\n",
      "tensor(302342.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.3438, grad_fn=<SubBackward0>)\n",
      "tensor(302340.5312, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.4375, grad_fn=<SubBackward0>)\n",
      "tensor(302338.0938, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.3438, grad_fn=<SubBackward0>)\n",
      "tensor(302335.7500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.3125, grad_fn=<SubBackward0>)\n",
      "tensor(302333.4375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.4375, grad_fn=<SubBackward0>)\n",
      "tensor(302331., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.1875, grad_fn=<SubBackward0>)\n",
      "tensor(302328.8125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.4375, grad_fn=<SubBackward0>)\n",
      "tensor(302326.3750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.2812, grad_fn=<SubBackward0>)\n",
      "tensor(302324.0938, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.2812, grad_fn=<SubBackward0>)\n",
      "tensor(302321.8125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.3125, grad_fn=<SubBackward0>)\n",
      "tensor(302319.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.2500, grad_fn=<SubBackward0>)\n",
      "tensor(302317.2500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.2812, grad_fn=<SubBackward0>)\n",
      "tensor(302314.9688, grad_fn=<SumBackward0>)\n",
      "--------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1562, grad_fn=<SubBackward0>)\n",
      "tensor(302312.8125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.1875, grad_fn=<SubBackward0>)\n",
      "tensor(302310.6250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.3125, grad_fn=<SubBackward0>)\n",
      "tensor(302308.3125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.3750, grad_fn=<SubBackward0>)\n",
      "tensor(302305.9375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.1250, grad_fn=<SubBackward0>)\n",
      "tensor(302303.8125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.3125, grad_fn=<SubBackward0>)\n",
      "tensor(302301.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.1875, grad_fn=<SubBackward0>)\n",
      "tensor(302299.3125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.1250, grad_fn=<SubBackward0>)\n",
      "tensor(302297.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.1875, grad_fn=<SubBackward0>)\n",
      "tensor(302295., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.0938, grad_fn=<SubBackward0>)\n",
      "tensor(302292.9062, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.2188, grad_fn=<SubBackward0>)\n",
      "tensor(302290.6875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.3125, grad_fn=<SubBackward0>)\n",
      "tensor(302288.3750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2., grad_fn=<SubBackward0>)\n",
      "tensor(302286.3750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.1250, grad_fn=<SubBackward0>)\n",
      "tensor(302284.2500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.0625, grad_fn=<SubBackward0>)\n",
      "tensor(302282.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.1875, grad_fn=<SubBackward0>)\n",
      "tensor(302280., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.1250, grad_fn=<SubBackward0>)\n",
      "tensor(302277.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.0312, grad_fn=<SubBackward0>)\n",
      "tensor(302275.8438, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.1562, grad_fn=<SubBackward0>)\n",
      "tensor(302273.6875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.0625, grad_fn=<SubBackward0>)\n",
      "tensor(302271.6250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.1875, grad_fn=<SubBackward0>)\n",
      "tensor(302269.4375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.0625, grad_fn=<SubBackward0>)\n",
      "tensor(302267.3750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.0625, grad_fn=<SubBackward0>)\n",
      "tensor(302265.3125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.1250, grad_fn=<SubBackward0>)\n",
      "tensor(302263.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.1250, grad_fn=<SubBackward0>)\n",
      "tensor(302261.0625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.0312, grad_fn=<SubBackward0>)\n",
      "tensor(302259.0312, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.0312, grad_fn=<SubBackward0>)\n",
      "tensor(302257., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2., grad_fn=<SubBackward0>)\n",
      "tensor(302255., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.0312, grad_fn=<SubBackward0>)\n",
      "tensor(302252.9688, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.0312, grad_fn=<SubBackward0>)\n",
      "tensor(302250.9375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.0312, grad_fn=<SubBackward0>)\n",
      "tensor(302248.9062, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.0938, grad_fn=<SubBackward0>)\n",
      "tensor(302246.8125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.0312, grad_fn=<SubBackward0>)\n",
      "tensor(302244.7812, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.9688, grad_fn=<SubBackward0>)\n",
      "tensor(302242.8125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2., grad_fn=<SubBackward0>)\n",
      "tensor(302240.8125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.9688, grad_fn=<SubBackward0>)\n",
      "tensor(302238.8438, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.9375, grad_fn=<SubBackward0>)\n",
      "tensor(302236.9062, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.9062, grad_fn=<SubBackward0>)\n",
      "tensor(302235., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.0625, grad_fn=<SubBackward0>)\n",
      "tensor(302232.9375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2., grad_fn=<SubBackward0>)\n",
      "tensor(302230.9375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.0625, grad_fn=<SubBackward0>)\n",
      "tensor(302228.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.8750, grad_fn=<SubBackward0>)\n",
      "tensor(302227., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2.0312, grad_fn=<SubBackward0>)\n",
      "tensor(302224.9688, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.9375, grad_fn=<SubBackward0>)\n",
      "tensor(302223.0312, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.9062, grad_fn=<SubBackward0>)\n",
      "tensor(302221.1250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.8750, grad_fn=<SubBackward0>)\n",
      "tensor(302219.2500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.9375, grad_fn=<SubBackward0>)\n",
      "tensor(302217.3125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(2., grad_fn=<SubBackward0>)\n",
      "tensor(302215.3125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.9062, grad_fn=<SubBackward0>)\n",
      "tensor(302213.4062, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.8750, grad_fn=<SubBackward0>)\n",
      "tensor(302211.5312, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.9688, grad_fn=<SubBackward0>)\n",
      "tensor(302209.5625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.9062, grad_fn=<SubBackward0>)\n",
      "tensor(302207.6562, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.9688, grad_fn=<SubBackward0>)\n",
      "tensor(302205.6875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.8750, grad_fn=<SubBackward0>)\n",
      "tensor(302203.8125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.8750, grad_fn=<SubBackward0>)\n",
      "tensor(302201.9375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.8125, grad_fn=<SubBackward0>)\n",
      "tensor(302200.1250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.7812, grad_fn=<SubBackward0>)\n",
      "tensor(302198.3438, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.8438, grad_fn=<SubBackward0>)\n",
      "tensor(302196.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.8125, grad_fn=<SubBackward0>)\n",
      "tensor(302194.6875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.9375, grad_fn=<SubBackward0>)\n",
      "tensor(302192.7500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.9375, grad_fn=<SubBackward0>)\n",
      "tensor(302190.8125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.8125, grad_fn=<SubBackward0>)\n",
      "tensor(302189., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.7500, grad_fn=<SubBackward0>)\n",
      "tensor(302187.2500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.8125, grad_fn=<SubBackward0>)\n",
      "tensor(302185.4375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.9375, grad_fn=<SubBackward0>)\n",
      "tensor(302183.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.7500, grad_fn=<SubBackward0>)\n",
      "tensor(302181.7500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.8750, grad_fn=<SubBackward0>)\n",
      "tensor(302179.8750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.8125, grad_fn=<SubBackward0>)\n",
      "tensor(302178.0625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.8125, grad_fn=<SubBackward0>)\n",
      "tensor(302176.2500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.8750, grad_fn=<SubBackward0>)\n",
      "tensor(302174.3750, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.7500, grad_fn=<SubBackward0>)\n",
      "tensor(302172.6250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.8438, grad_fn=<SubBackward0>)\n",
      "tensor(302170.7812, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.7812, grad_fn=<SubBackward0>)\n",
      "tensor(302169., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.9062, grad_fn=<SubBackward0>)\n",
      "tensor(302167.0938, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.7812, grad_fn=<SubBackward0>)\n",
      "tensor(302165.3125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.8125, grad_fn=<SubBackward0>)\n",
      "tensor(302163.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.7812, grad_fn=<SubBackward0>)\n",
      "tensor(302161.7188, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.7812, grad_fn=<SubBackward0>)\n",
      "tensor(302159.9375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.7500, grad_fn=<SubBackward0>)\n",
      "tensor(302158.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.7500, grad_fn=<SubBackward0>)\n",
      "tensor(302156.4375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.6875, grad_fn=<SubBackward0>)\n",
      "tensor(302154.7500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.7812, grad_fn=<SubBackward0>)\n",
      "tensor(302152.9688, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.6562, grad_fn=<SubBackward0>)\n",
      "tensor(302151.3125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.8125, grad_fn=<SubBackward0>)\n",
      "tensor(302149.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.7500, grad_fn=<SubBackward0>)\n",
      "tensor(302147.7500, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.7812, grad_fn=<SubBackward0>)\n",
      "tensor(302145.9688, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.5625, grad_fn=<SubBackward0>)\n",
      "tensor(302144.4062, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.7812, grad_fn=<SubBackward0>)\n",
      "tensor(302142.6250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.6875, grad_fn=<SubBackward0>)\n",
      "tensor(302140.9375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.7188, grad_fn=<SubBackward0>)\n",
      "tensor(302139.2188, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.7188, grad_fn=<SubBackward0>)\n",
      "tensor(302137.5000, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.6875, grad_fn=<SubBackward0>)\n",
      "tensor(302135.8125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.8125, grad_fn=<SubBackward0>)\n",
      "tensor(302134., grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.6875, grad_fn=<SubBackward0>)\n",
      "tensor(302132.3125, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.6250, grad_fn=<SubBackward0>)\n",
      "tensor(302130.6875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.7188, grad_fn=<SubBackward0>)\n",
      "tensor(302128.9688, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.7812, grad_fn=<SubBackward0>)\n",
      "tensor(302127.1875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.6250, grad_fn=<SubBackward0>)\n",
      "tensor(302125.5625, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.6250, grad_fn=<SubBackward0>)\n",
      "tensor(302123.9375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.6562, grad_fn=<SubBackward0>)\n",
      "tensor(302122.2812, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.6562, grad_fn=<SubBackward0>)\n",
      "tensor(302120.6250, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.5938, grad_fn=<SubBackward0>)\n",
      "tensor(302119.0312, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.6875, grad_fn=<SubBackward0>)\n",
      "tensor(302117.3438, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.6562, grad_fn=<SubBackward0>)\n",
      "tensor(302115.6875, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.6562, grad_fn=<SubBackward0>)\n",
      "tensor(302114.0312, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "tensor(1.5938, grad_fn=<SubBackward0>)\n",
      "tensor(302112.4375, grad_fn=<SumBackward0>)\n",
      "--------\n",
      "finished gradient descent on iteration 500\n",
      "with loss equal tensor(302112.4375, grad_fn=<SumBackward0>)\n",
      "CPU times: user 10.9 s, sys: 186 ms, total: 11.1 s\n",
      "Wall time: 5.5 s\n"
     ]
    }
   ],
   "source": [
    "def gradientDescentTorch(y, x, maxIterations = 500, tolerance=0.0000001):\n",
    "    alpha = 0.00000001\n",
    "    w = torch.randn(x.shape[1], 1, device=device, requires_grad=True)\n",
    "    loss = float('Inf')\n",
    "    for i in range(maxIterations):\n",
    "        y_pred = linear(x, w)\n",
    "        lastLoss = loss\n",
    "        loss = (y_pred - y).pow(2).sum()\n",
    "        if loss < tolerance:\n",
    "            maxIterations = i\n",
    "            break\n",
    "        lossDelta = lastLoss - loss\n",
    "        print(lossDelta)\n",
    "#         if lossDelta < 500 and lossDelta > 0:\n",
    "#             alpha = alpha * 10\n",
    "        w.retain_grad()\n",
    "        loss.backward()\n",
    "#         if lossDelta < 0:\n",
    "#             w = w - (alpha*0.001)*w.grad\n",
    "#             print(\"Loss smaller than 0\")\n",
    "#         else:\n",
    "        w = w - alpha*w.grad\n",
    "        print(loss)\n",
    "        print(\"--------\")\n",
    "\n",
    "    \n",
    "    print(\"finished gradient descent on iteration \" + str(maxIterations))\n",
    "    print(\"with loss equal \" + str(loss))\n",
    "    return w\n",
    "\n",
    "%time tGD = gradientDescentTorch(y_train_tensor, x_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1.2562,  0.9243,  0.4724],\n",
       "         [ 0.7644,  0.1015, -1.4955],\n",
       "         [ 0.8127,  0.3179, -0.2380],\n",
       "         [-1.1483,  0.3693,  3.2355],\n",
       "         [ 0.9877,  0.8425,  1.5595]]), tensor([[-1.2986],\n",
       "         [-0.2923],\n",
       "         [-0.7623],\n",
       "         [-0.8785],\n",
       "         [-1.5118]])]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "inputs = np.stack((np.random.normal(0, 1, (1000)), \n",
    "              np.random.uniform(0, 1, (1000)), \n",
    "              np.random.normal(1,2, (1000))), axis=1)\n",
    "inputs = torch.from_numpy(inputs).float().to(device)\n",
    "targets = model(inputs)\n",
    "targets = np.asanyarray([[float(x + noise)] for x in targets])\n",
    "targets = torch.from_numpy(targets).float()\n",
    "\n",
    "w = torch.randn(1, 3, requires_grad=True)\n",
    "b = torch.randn(1, requires_grad=True)\n",
    "\n",
    "train_ds = TensorDataset(inputs, targets)\n",
    "train_ds[0:3]\n",
    "# Define data loader\n",
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3132, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "model = nn.Linear(3, 1)\n",
    "# Define optimizer\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
    "loss_fn = F.mse_loss\n",
    "loss = loss_fn(model(inputs), targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.randn(1, 3, requires_grad=True)\n",
    "b = torch.randn(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "Training loss:  tensor(0.0010, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "tolerance = 0.01\n",
    "for epoch in range(num_epochs):\n",
    "        loss_total = 0\n",
    "        for xb,yb in train_dl:\n",
    "            # Generate predictions\n",
    "            pred = model(xb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "            loss_total += loss\n",
    "            # Perform gradient descent\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        loss_avg = loss_total/(len(train_dl))\n",
    "        print(loss_avg)\n",
    "        if loss_avg < tolerance:\n",
    "            break\n",
    "print('Training loss: ', loss_fn(model(inputs), targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement GD using pytorch automatic differentiation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To this end the variable with respect to which the gradient will be calculated, ``t_w`` in this case, must have attribute\n",
    "``requires_grad`` set to ``True`` (``t_w.require_grad=True``)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The torch will automatically track any expression containing ``t_w`` and store its computational graph. The method ``backward()`` can be run on the final expression to back propagate the gradient e.g. ``loss.backward()``. Then the gradient is accesible as ``t_w.grad``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
